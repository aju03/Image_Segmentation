{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SemanticConvnet as sc\n",
    "import DataLoader as dl\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sc.Net.create()\n",
    "# torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 1, 512, 512]) torch.Size([1, 262144])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import DataLoader as dl\n",
    "dataloader = dl.LitsDataSet.create(root_dir = 'VolSegData/', batch_size = 1,shuffle = True, num_workers = 0)\n",
    "data = None\n",
    "label = None\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "        print(i_batch, sample_batched['scan'].size(),\n",
    "          sample_batched['segmentation'].size())\n",
    "        if i_batch == 0:\n",
    "            data = sample_batched['scan']\n",
    "            data = data\n",
    "            label = sample_batched['segmentation']\n",
    "            label = label\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = torch.randn(1,1,512,512)\n",
    "# label = torch.randn(1,512*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outLabel = model.forward(data)\n",
    "outLabel = outLabel.view(1, 512*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 262144])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outLabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SparseAdam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.DoubleTensor'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outLabel.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outLabel = outLabel.long()\n",
    "# outLabel.type()\n",
    "# label = label.long()\n",
    "# label.type()\n",
    "# loss = criterion(outLabel.long(),label.float())\n",
    "#mse\n",
    "loss = criterion(label,label)\n",
    "#ce\n",
    "# loss = criterion(outLabel.float(),label.long())\n",
    "loss = Variable(loss, requires_grad = True)\n",
    "try:\n",
    "    loss.backward()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.031\n",
      "[1,     2] loss: 0.000\n",
      "[1,     3] loss: 0.000\n",
      "[1,     4] loss: 0.000\n",
      "[1,     5] loss: 0.000\n",
      "[1,     6] loss: 0.100\n",
      "[1,     7] loss: 0.077\n",
      "[1,     8] loss: 0.000\n",
      "[1,     9] loss: 0.005\n",
      "[1,    10] loss: 0.000\n",
      "[1,    11] loss: 0.000\n",
      "[2,     1] loss: 0.000\n",
      "[2,     2] loss: 0.000\n",
      "[2,     3] loss: 0.136\n",
      "[2,     4] loss: 0.006\n",
      "[2,     5] loss: 0.090\n",
      "[2,     6] loss: 0.000\n",
      "[2,     7] loss: 0.106\n",
      "[2,     8] loss: 0.000\n",
      "[2,     9] loss: 0.000\n",
      "[2,    10] loss: 0.000\n",
      "[2,    11] loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i_batch,sample_batched in enumerate(dataloader):\n",
    "        inputs , label = sample_batched['scan'], sample_batched['segmentation']\n",
    "        output = model.forward(inputs)\n",
    "        loss = criterion(output, label)\n",
    "        loss = Variable(loss, requires_grad = True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #stat\n",
    "        running_loss = loss.item()\n",
    "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i_batch + 1, running_loss))\n",
    "        if i_batch == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.randn(1,1,512,512).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader.py           SemanticConvnet.py      main.py\r\n",
      "DataProcess.py          Untitled.ipynb          \u001b[34mtestBatch\u001b[m\u001b[m/\r\n",
      "DetailingNetwork.ipynb  \u001b[34mVolSegData\u001b[m\u001b[m/             \u001b[34mtrainBatch1\u001b[m\u001b[m/\r\n",
      "README.md               \u001b[34m__pycache__\u001b[m\u001b[m/            \u001b[34mtrainBatch2\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir tempFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader.py           Untitled.ipynb          \u001b[34mtestBatch\u001b[m\u001b[m/\r\n",
      "DataProcess.py          \u001b[34mVolSegData\u001b[m\u001b[m/             \u001b[34mtrainBatch1\u001b[m\u001b[m/\r\n",
      "DetailingNetwork.ipynb  \u001b[34m__pycache__\u001b[m\u001b[m/            \u001b[34mtrainBatch2\u001b[m\u001b[m/\r\n",
      "README.md               main.py\r\n",
      "SemanticConvnet.py      \u001b[34mtempFolder\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'checkpoints/m1.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1.torch\r\n"
     ]
    }
   ],
   "source": [
    "ls tempFolder/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = sc.Net.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb.load_state_dict(torch.load('checkpoints/m1.torch'),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64, grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb.forward(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14918"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
